, 
```
Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, chi2

Load data
df = pd.read_csv('data.csv')

Preprocess data
df = df.dropna()  # drop rows with missing values
df = df.astype({'label': 'category'})  # convert label to categorical

Split data into features (X) and labels (y)
X = df.drop('label', axis=1)
y = df['label']

Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

Dimensionality reduction using PCA
pca = PCA(n_components=0.95)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

Feature selection using chi-squared test
selector = SelectKBest(chi2, k=10)
X_train_selected = selector.fit_transform(X_train_pca, y_train)
X_test_selected = selector.transform(X_test_pca)

Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_selected, y_train)
y_pred_rf = rf.predict(X_test_selected)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f'Random Forest Accuracy: {accuracy_rf:.3f}')
print(classification_report(y_test, y_pred_rf))
print(confusion_matrix(y_test, y_pred_rf))

Hyperparameter tuning for Random Forest
param_grid_rf = {'n_estimators': [10, 50, 100, 200], 'max_depth': [None, 5, 10, 15]}
grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5)
grid_search_rf.fit(X_train_selected, y_train)
print(f'Best Parameters for Random Forest: {grid_search_rf.best_params_}')
print(f'Best Score for Random Forest: {grid_search_rf.best_score_}')

Support Vector Machine (SVM)
svm_model = svm.SVC(kernel='rbf', C=1)
svm_model.fit(X_train_selected, y_train)
y_pred_svm = svm_model.predict(X_test_selected)
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f'SVM Accuracy: {accuracy_svm:.3f}')
print(classification_report(y_test, y_pred_svm))
print(confusion_matrix(y_test, y_pred_svm))

Hyperparameter tuning for SVM
param_grid_svm = {'kernel': ['linear', 'rbf', 'poly'], 'C': [0.1, 1, 10]}
grid_search_svm = GridSearchCV(svm.SVC(), param_grid_svm, cv=5)
grid_search_svm.fit(X_train_selected, y_train)
print(f'Best Parameters for SVM: {grid_search_svm.best_params_}')
print(f'Best Score for SVM: {grid_search_svm.best_score_}')

Neural Network
model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(X_train_selected.shape[1],)))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train_selected, y_train, epochs=10, batch_size=128, validation_data=(X_test_selected, y_test))
loss, accuracy_nn = model.evaluate(X_test_selected, y_test)
print(f'Neural Network Accuracy: {accuracy_nn:.3f}')
print(classification_report(y_test, model.predict(X_test_selected).round()))
print(confusion_matrix(y_test, model.predict(X_test_selected).round()))

Hyperparameter tuning for Neural Network
from kerastuner.tuners import RandomSearch
from kerastuner import HyperParameters

def build_model(hp):
    model = Sequential()
    model.add(Dense(units=hp.Int('units', min_value=32, max_value=128, step=32), activation='relu', input_shape=(X_train_selected.shape[1],)))
    model.add(Dense(units=hp.Int('units2', min_value=16, max_value=64, step=16), activation='relu'))
    model.add(Dense(1
```
